apiVersion: 1
groups:
- name: OSD
  folder: Ceph-Alert
  interval: 10s
  rules:
  - uid: denfoui8szbb4f
    title: CephOSDFull
    condition: C
    data:
    - refId: A
      relativeTimeRange:
        from: 600
        to: 0
      datasourceUid: aeoesbkofng1sf
      model:
        editorMode: code
        expr: ceph_health_detail{name="OSD_FULL"} > 0
        instant: true
        intervalMs: 1000
        legendFormat: __auto
        maxDataPoints: 43200
        range: false
        refId: A
    - refId: C
      datasourceUid: __expr__
      model:
        conditions:
        - evaluator:
            params:
            - 0
            type: gt
          operator:
            type: and
          query:
            params:
            - C
          reducer:
            params: []
            type: last
          type: query
        datasource:
          type: __expr__
          uid: __expr__
        expression: A
        intervalMs: 1000
        maxDataPoints: 43200
        refId: C
        type: threshold
    noDataState: OK
    execErrState: Error
    for: 1m
    keepFiringFor: 5m
    annotations:
      description: An OSD has reached the FULL threshold. Writes to pools that share
        the affected OSD will be blocked. Use 'ceph health detail' and 'ceph osd df'
        to identify the problem. To resolve, add capacity to the affected OSD's failure
        domain, restore down/out OSDs, or delete unwanted data.
      summary: OSD full, writes blocked
    labels:
      severity: critical
      storage: ceph
    isPaused: false
    notification_settings:
      receiver: grafana-default-email
